{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![@mikegchambers](../../images/header.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "\n",
    "In this notebook, we explore Convolutional Neural Networks using TensorFlow and a custom Lego dataset.\n",
    "\n",
    "![Lens](lens.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UPDATE: Select the `conda_tensorflow2_p310` kernel when prompted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# tf.logging.set_verbosity(tf.logging.ERROR) # <- Update - Reomved this line as it's no longer compatible with the version of TF used.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Data\n",
    "\n",
    "Let's load out dataset.  Here we use Numpy to load in two datasets that have been created and saved previously using Numpy.  We have some images, and some labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('images_48.npy')\n",
    "y = np.load('labels_48.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use scikit-learn to randomize the data, and split it into a training and a test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels for the data are set to integer values.  Let's create a list with the official Lego part numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['lg_2412b', 'lg_3001', 'lg_3002', 'lg_3003', 'lg_3004', 'lg_3005', 'lg_3010', 'lg_3622', 'lg_3648', 'lg_3839']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look at the data.  This time, we loop through the data to find the first occurance of each class.  This way we don't leave it to chance, and we have a referance of what each brick will look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "for b in range(10):\n",
    "    for i in range(len(y_train)):\n",
    "        if y_train[i] == b:\n",
    "            plt.subplot(2,5,b+1)\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            plt.imshow(X_train[i], cmap=plt.cm.binary)\n",
    "            plt.xlabel(\"{} ({})\".format(class_names[y_train[i]], b))\n",
    "            break\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Model\n",
    "\n",
    "In this lesson we use a slightly different notation to create a Keras Sequential network.  Either method will work, this is not a CNN thing.  \n",
    "\n",
    "The difference is that we are now including convolutional layers, and max pooling layers.\n",
    "\n",
    "You can, and should experiment, by adding layers, removing layers and changing the size of layers to see what effect it has on the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(48, (3, 3), activation='relu', input_shape=(48, 48, 1)))\n",
    "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(64, (9, 9), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we compile the model with our usual parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train... (again we store the output so we can graph it later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = model.fit(X_train.reshape(-1, 48, 48,1), y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Summary Graph\n",
    "\n",
    "Let's plot accuracy and loss over the epochs.  Does it look promising?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(e.history['accuracy']) # <- Note minor change here from `acc` to `accuracy`. \n",
    "plt.plot(e.history['loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "Now let's ask the model to evaluate itself using the remaining test data that it's not seen before.\n",
    "\n",
    "How well does it do?  Does the accuracy match the training accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test.reshape(-1, 48, 48, 1), y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mass Prediction Results\n",
    "\n",
    "We're going to display a graph of the first set of predictions.  But we're going to be a little more sophisticated this time and display the confidence of the prediction as well.\n",
    "\n",
    "To do that we are first going to define a couple of functions to help with the display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will display the image \n",
    "# and color the label in ref to a correct prediction:\n",
    "\n",
    "def plot_image(i, predictions_array, true_label, img):\n",
    "    predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(img, cmap=plt.cm.binary)\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    if predicted_label == true_label:\n",
    "        color = 'green'\n",
    "    else:\n",
    "        color = 'red'\n",
    "    # Print a label with 'predicted class', 'probability %', 'actual class'\n",
    "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                100*np.max(predictions_array),\n",
    "                                class_names[true_label]),\n",
    "                                color=color)\n",
    "\n",
    "# This function will display the prediction results in a bar graph:\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "    predictions_array, true_label = predictions_array[i], true_label[i]\n",
    "    plt.xticks(range(10))\n",
    "    plt.yticks([])\n",
    "    plot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
    "    plt.ylim([0, 1])\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    plot[predicted_label].set_color('red')\n",
    "    plot[true_label].set_color('green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets get predictions for all of our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test.reshape(-1, 48, 48, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now display the grid of results, using our defined display functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = 4\n",
    "num_cols = 3\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i in range(num_images):\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "  plot_image(i, predictions, y_test, X_test)\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "  plot_value_array(i, predictions, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with a real photo\n",
    "\n",
    "Ok, so the model looks to be doing OK with test render images.  What about real-world images.\n",
    "\n",
    "Let's load some more libraries and have a go.  These extra libraries are mostly about pre-processing the image to be the same size as our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import PIL\n",
    "import PIL.ImageOps\n",
    "from PIL import Image, ImageEnhance\n",
    "from skimage.util import random_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets load the photo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the data from disk:\n",
    "\n",
    "img = cv2.imread('lg_3622.jpg')\n",
    "# img = cv2.imread('lg_3004.jpg')\n",
    "# img = cv2.imread('lg_3002.jpg')\n",
    "\n",
    "## Convert the image to a Pillow image:\n",
    "\n",
    "img = Image.fromarray(img)\n",
    "\n",
    "\n",
    "## Quickly plot the original image so we can see what it looks like\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While most of this code is optional, still run this cell as there is at least one line there!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This section can be un-commented as required to perform image enhancement:\n",
    "\n",
    "# enhancer = ImageEnhance.Contrast(img)\n",
    "# factor = 0.3\n",
    "# img = enhancer.enhance(factor)\n",
    "\n",
    "# enhancer = ImageEnhance.Brightness(img)\n",
    "# factor = 1.4\n",
    "# img = enhancer.enhance(factor)\n",
    "\n",
    "# enhancer = ImageEnhance.Sharpness(img)\n",
    "# factor = 5\n",
    "# img = enhancer.enhance(factor)\n",
    "\n",
    "img = np.asarray(img)\n",
    "\n",
    "## Adding noise to the iamge can sometimes help \n",
    "## (but you would need to have added noise to the training data too)\n",
    "\n",
    "# img = random_noise(img, mode='gaussian', var=0.001)\n",
    "# img = np.array(255*img, dtype = 'uint8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we convert the image to grayscale, change the size (the photo needed to be square to work well)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.fromarray(img)\n",
    "\n",
    "img = PIL.ImageOps.invert(img)\n",
    "img = img.convert('L')\n",
    "img.thumbnail((48, 48))\n",
    "\n",
    "img = np.array(img)\n",
    "img = img.astype('float32')\n",
    "data = img/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does our processed image look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(5,5,1)\n",
    "plt.imshow(data, cmap=plt.cm.binary)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's pass the processed image to our model and see what it thinks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " p = model.predict(data.reshape(1, 48, 48, 1)) # <- UPDATE: Minor update to the reshape here.\n",
    "pp = p.argmax()\n",
    "print(\"This is a photo of brick {} ({})\".format(class_names[pp], pp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can try with your own images of Lego bricks (that the model is trained on).  Do you have any success?  The brick needs to be lit in the same way, and be generally the same size in the frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
