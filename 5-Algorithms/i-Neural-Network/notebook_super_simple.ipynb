{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![@mikegchambers](../../images/header.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Neural Network\n",
    "\n",
    "In this notebook, we explore a simple Neural Network, also known as a Perceptron.   We use TensorFlow/Keras to build the network and scikit-learn to prep some data.\n",
    "\n",
    "![Network](network.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UPDATE: Select the `conda_tensorflow2_p310` kernel when prompted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# UPADTE: We turn off GPU support, although this does not seem to suppress all warnings! \n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# tf.logging.set_verbosity(tf.logging.ERROR) # <- Update - Reomved this line as it's no longer compatible with the version of TF used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Data\n",
    "\n",
    "Again, to be in complete control of the data within this example, we create it ourselves.\n",
    "\n",
    "In this cell we create a template for the data, we will then pultiply this template by random values to get an example set of MCSD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = np.array([[1.0,1.0,\n",
    "                      0.1,0.1],\n",
    "                     \n",
    "                     [0.1,1.0,\n",
    "                      0.1,1.0],\n",
    "                     \n",
    "                     [0.1,0.1,\n",
    "                      1.0,1.0],\n",
    "                     \n",
    "                     [1.0,0.1,\n",
    "                      1.0,0.1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the templates to generate samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for _ in range(2000):\n",
    "    for i in range(len(template)):\n",
    "        r = np.array([random.uniform(0.5, 1), random.uniform(0.5, 1), random.uniform(0.5, 1), random.uniform(0.5, 1)])\n",
    "        X.append(template[i] * r)\n",
    "        y.append(i)\n",
    "        \n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's visualize what we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "for i in range(16*4):\n",
    "    plt.subplot(4,16,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(X[i].reshape(2,2), cmap='Greys')\n",
    "    plt.xlabel(y[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the best outcome we need to shuffle the data so that the network dosn't get uses to the order in which samples come its way.  Also we could do with a small amount of data to be kept back for testing.  \n",
    "\n",
    "We can do both actions in one step with scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's visualize what we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "for i in range(16*4):\n",
    "    plt.subplot(4,16,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(X_train[i].reshape(2,2), cmap='Greys')\n",
    "    plt.xlabel(y_train[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Model\n",
    "\n",
    "We are using a library within TensorFlow called Keras.  This does much of the heavy lifting involved in creating the network, leaving us to concentrate on the parts that matter to us.  \n",
    "\n",
    "First, in this code cell, we clear the TensorFlow session.  This is only necessary if we come to rerun this cell and we want to be sure that we are starting again.\n",
    "\n",
    "Then we use Keras Sequential to create a network with the size we want.  The will be (unless you change it) 4 input neurons, and 4 output neurons.\n",
    "\n",
    "Finally, we call `model.complie` passing in the values we want for our `optimizer` which is the process we want to use in backpropagation, `loss` which is the type of loss or cost function we want to use, and lastly we set the metrics we want to record as the model trains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear the session (incase we run multiple times)\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Create a TF sequential model with Keras\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.InputLayer(input_shape=(4,)), # <- UPDATE: Minor change for version compatability. \n",
    "  tf.keras.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like many times before, we call `model.fit`.  After passing in the data, we say how many epochs we want to run.\n",
    "\n",
    "We also assign the output of the operation to a variable `e` so that we can get access to the metrics later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = model.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well that's more output than we are used to in a training model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How well did it train?\n",
    "Remember when we called `fit` was assigned the output of the operation to the variable `e`.  Let's graph what we have in recorded in `e`, and get an idea of how the training went."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(e.history['loss'], c='red')\n",
    "plt.plot(e.history['accuracy'], c='green') # <- Note minor change here from `acc` to `accuracy`.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = 0\n",
    "\n",
    "# UPADTE: \n",
    "# Ensure that the input is 2-dimensional\n",
    "# `X_test[test]` is a single instance and should be reshaped to have 2 dimensions\n",
    "p = model.predict([X_test[test].reshape(1, -1)])\n",
    "pred = p.argmax()\n",
    "\n",
    "plt.imshow(X_test[test].reshape(2,2), cmap='Greys')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.xlabel(\"{}:({})\".format(pred, y_test[test]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh... one more thing...\n",
    "\n",
    "# Look inside the Model\n",
    "\n",
    "If you're curious how I got the values out of the model to be able to draw the animations in the previous lessons, it starts here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_weights()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if you're even more curious, the code used to make the animations can be found here: https://github.com/learn-mikegchambers-com/ModelAnimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
