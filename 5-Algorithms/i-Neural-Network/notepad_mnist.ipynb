{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![@mikegchambers](../../images/header.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The super famous:\n",
    "# MNIST Hand Written Dataset \n",
    "\n",
    "In this notebook, we walk the right of passage that is the MNIST Hand Written Dataset.  We use a simple Neural Network, also known as a Perceptron.   We use TensorFlow/Keras to build the network.\n",
    "\n",
    "![MNIST Network](mnist-network.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UPDATE: Select the `conda_tensorflow2_p310` kernel when prompted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# UPADTE: We turn off GPU support, although this does not seem to suppress all warnings! \n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# tf.logging.set_verbosity(tf.logging.ERROR) # <- Update - Reomved this line as it's no longer compatible with the version of TF used.\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Data\n",
    "\n",
    "This dataset is so famous and widly used, that it's built in to pretty much every framework there is, including TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's visualize what we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "for i in range(16*4):\n",
    "    plt.subplot(4,16,i+1)\n",
    "    plt.imshow(x_train[i], cmap=\"Greys\")\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.xlabel(\"{}\".format(str(y_train[i])))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Model\n",
    "\n",
    "We are using a library within TensorFlow called Keras. This does much of the heavy lifting involved in creating the network, leaving us to concentrate on the parts that matter to us.\n",
    "\n",
    "First, in this code cell, we clear the TensorFlow session. This is only necessary if we come to rerun this cell and we want to be sure that we are starting again.\n",
    "\n",
    "Then we use Keras Sequential to create a network with the size we want.\n",
    "\n",
    "Finally, we call model.complie passing in the values we want for our optimizer which is the process we want to use in backpropagation, loss which is the type of loss or cost function we want to use, and lastly we set the metrics we want to record as the model trains.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like many times before, we call model.fit. After passing in the data, we say how many epochs we want to run.\n",
    "\n",
    "We also assign the output of the operation to a variable e so that we can get access to the metrics later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "e = model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How well did it train?\n",
    "Remember when we called `fit` was assigned the output of the operation to the variable `e`.  Let's graph what we have in recorded in `e`, and get an idea of how the training went."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(e.history['loss'], c='red')\n",
    "plt.plot(e.history['accuracy'], c='green') # <- Note minor change here from `acc` to `accuracy`.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also call `evaluate` on our model and pass in the test data we saved.  The model will (quickly) evaluate itself against all the test data we have left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's be more visual.  Here we loop through the first few images in our test set.  We  perform a `model.predict` on the image, then display it labeled with the prediction and the known truth.  We will change the color of the label green if it's correct, and red if it's wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# UPDATE: This code has been updated to work with newer versions of the TF library.\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i in range(16 * 4):\n",
    "    plt.subplot(4, 16, i + 1)\n",
    "    \n",
    "    # Reshape the input to 2D shape expected by the model (28x28)\n",
    "    input_data = x_test[i].reshape(1, 28, 28)  # Reshaping to (1, 28, 28)\n",
    "    p = model.predict(input_data)\n",
    "    pred = p.argmax()\n",
    "    \n",
    "    plt.imshow(x_test[i].reshape(28, 28), cmap=\"Greys\")  # Reshaping for display\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    if pred == y_test[i]:\n",
    "        color = 'green'\n",
    "    else:\n",
    "        color = 'red'\n",
    "    \n",
    "    plt.xlabel(\"{} ({})\".format(str(pred), str(y_test[i])), color=color)    \n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
